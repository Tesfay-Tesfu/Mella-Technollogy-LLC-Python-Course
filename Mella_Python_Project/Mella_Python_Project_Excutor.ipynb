{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fd5894-93e5-4e72-afa8-f11089628322",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    border: 3px solid #4CAF50;  /* Green border */\n",
    "    background: linear-gradient(90deg, #ffcccb, #ffe066, #b3ffb3);  /* Colorful gradient */\n",
    "    padding: 20px;\n",
    "    border-radius: 15px;\n",
    "    text-align: center;\n",
    "    font-family: Arial, sans-serif;\n",
    "\">\n",
    "    <h2 style=\"\n",
    "        font-weight: bold;\n",
    "        font-size: 28px;\n",
    "        color: #1a1a1a;\n",
    "        text-shadow: 2px 2px 4px #888888;\n",
    "    \">\n",
    "        Congratulation to all <span style=\"color: #FF4500;\">1st Batch</span> \n",
    "        <span style=\"color: #4169E1;\">Mella-Python-Data-Analytics-Group</span>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cd1f3e-7492-42cc-bcde-5bd878d289a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Aru_New_Future\\Mella-Technollogy-LLC-Python-Course-main\\Mella-Technollogy-LLC-Python-Course-main\\Week_8\\Mella_python_data_analytics.py:41: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Aru_New_Future\\Mella-Technollogy-LLC-Python-Course-main\\Mella-Technollogy-LLC-Python-Course-main\\Week_8\\Mella_python_data_analytics.py:41: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "C:\\Aru_New_Future\\Mella-Technollogy-LLC-Python-Course-main\\Mella-Technollogy-LLC-Python-Course-main\\Week_8\\Mella_python_data_analytics.py:41: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 CSV files to process\n",
      "\n",
      "============================================================\n",
      "PROCESSING FILE: Aweather.csv\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:30: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (45841, 138)\n",
      "Original columns: ['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'PRCP', 'PRCP_ATTRIBUTES', 'SNOW', 'SNOW_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES', 'TMAX', 'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES', 'ACMH', 'ACMH_ATTRIBUTES', 'ACSH', 'ACSH_ATTRIBUTES', 'ADPT', 'ADPT_ATTRIBUTES', 'ASLP', 'ASLP_ATTRIBUTES', 'ASTP', 'ASTP_ATTRIBUTES', 'AWBT', 'AWBT_ATTRIBUTES', 'AWND', 'AWND_ATTRIBUTES', 'DAEV', 'DAEV_ATTRIBUTES', 'DAPR', 'DAPR_ATTRIBUTES', 'DAWM', 'DAWM_ATTRIBUTES', 'EVAP', 'EVAP_ATTRIBUTES', 'FMTM', 'FMTM_ATTRIBUTES', 'FRGB', 'FRGB_ATTRIBUTES', 'FRGT', 'FRGT_ATTRIBUTES', 'FRTH', 'FRTH_ATTRIBUTES', 'GAHT', 'GAHT_ATTRIBUTES', 'MDEV', 'MDEV_ATTRIBUTES', 'MDPR', 'MDPR_ATTRIBUTES', 'MDWM', 'MDWM_ATTRIBUTES', 'PGTM', 'PGTM_ATTRIBUTES', 'PSUN', 'PSUN_ATTRIBUTES', 'RHAV', 'RHAV_ATTRIBUTES', 'RHMN', 'RHMN_ATTRIBUTES', 'RHMX', 'RHMX_ATTRIBUTES', 'TAVG', 'TAVG_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WDF1', 'WDF1_ATTRIBUTES', 'WDF2', 'WDF2_ATTRIBUTES', 'WDF5', 'WDF5_ATTRIBUTES', 'WDFG', 'WDFG_ATTRIBUTES', 'WDFM', 'WDFM_ATTRIBUTES', 'WDMV', 'WDMV_ATTRIBUTES', 'WESD', 'WESD_ATTRIBUTES', 'WSF1', 'WSF1_ATTRIBUTES', 'WSF2', 'WSF2_ATTRIBUTES', 'WSF5', 'WSF5_ATTRIBUTES', 'WSFG', 'WSFG_ATTRIBUTES', 'WSFM', 'WSFM_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES', 'WT02', 'WT02_ATTRIBUTES', 'WT03', 'WT03_ATTRIBUTES', 'WT04', 'WT04_ATTRIBUTES', 'WT05', 'WT05_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES', 'WT07', 'WT07_ATTRIBUTES', 'WT08', 'WT08_ATTRIBUTES', 'WT09', 'WT09_ATTRIBUTES', 'WT10', 'WT10_ATTRIBUTES', 'WT11', 'WT11_ATTRIBUTES', 'WT13', 'WT13_ATTRIBUTES', 'WT14', 'WT14_ATTRIBUTES', 'WT15', 'WT15_ATTRIBUTES', 'WT16', 'WT16_ATTRIBUTES', 'WT17', 'WT17_ATTRIBUTES', 'WT18', 'WT18_ATTRIBUTES', 'WT19', 'WT19_ATTRIBUTES', 'WT21', 'WT21_ATTRIBUTES', 'WT22', 'WT22_ATTRIBUTES', 'WV01', 'WV01_ATTRIBUTES', 'WV03', 'WV03_ATTRIBUTES', 'WV07', 'WV07_ATTRIBUTES']\n",
      "Keeping columns: ['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'PRCP', 'PRCP_ATTRIBUTES', 'SNOW', 'SNOW_ATTRIBUTES']\n",
      "Shape after column selection: (45841, 10)\n",
      "Successfully converted column 'DATE' to datetime using format '%Y-%m-%d'\n",
      "Removed 0 duplicate rows. Remaining rows: 45841\n",
      "Shape after cleaning: (45841, 10)\n",
      "\n",
      "Creating plots for Aweather.csv...\n",
      "Saved summary plot: Aweather_summary.png\n",
      "  Saved LATITUDE distribution plot\n",
      "  Saved LONGITUDE distribution plot\n",
      "  Saved ELEVATION distribution plot\n",
      "  Saved PRCP distribution plot\n",
      "  Saved SNOW distribution plot\n",
      "\n",
      "Exporting Aweather.csv to SQL Server...\n",
      "Successfully exported to table: Weather_Aweather\n",
      "Export logged to: C:\\Aru_New_Future\\Mella-Technollogy-LLC-Python-Course-main\\Mella-Technollogy-LLC-Python-Course-main\\Backups\\Week_2\\Multiple_Files\\data\\export_log.csv\n",
      "\n",
      "Completed processing: Aweather.csv\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROCESSING FILE: Bweather.csv\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:30: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (32294, 144)\n",
      "Original columns: ['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'PRCP', 'PRCP_ATTRIBUTES', 'SNOW', 'SNOW_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES', 'TMAX', 'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES', 'ACMH', 'ACMH_ATTRIBUTES', 'ACSH', 'ACSH_ATTRIBUTES', 'ADPT', 'ADPT_ATTRIBUTES', 'ASLP', 'ASLP_ATTRIBUTES', 'ASTP', 'ASTP_ATTRIBUTES', 'AWBT', 'AWBT_ATTRIBUTES', 'AWND', 'AWND_ATTRIBUTES', 'DAEV', 'DAEV_ATTRIBUTES', 'DAWM', 'DAWM_ATTRIBUTES', 'EVAP', 'EVAP_ATTRIBUTES', 'FMTM', 'FMTM_ATTRIBUTES', 'FRGT', 'FRGT_ATTRIBUTES', 'MDEV', 'MDEV_ATTRIBUTES', 'MDWM', 'MDWM_ATTRIBUTES', 'MNPN', 'MNPN_ATTRIBUTES', 'MXPN', 'MXPN_ATTRIBUTES', 'PGTM', 'PGTM_ATTRIBUTES', 'PSUN', 'PSUN_ATTRIBUTES', 'RHAV', 'RHAV_ATTRIBUTES', 'RHMN', 'RHMN_ATTRIBUTES', 'RHMX', 'RHMX_ATTRIBUTES', 'TAVG', 'TAVG_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WDF1', 'WDF1_ATTRIBUTES', 'WDF2', 'WDF2_ATTRIBUTES', 'WDF5', 'WDF5_ATTRIBUTES', 'WDFG', 'WDFG_ATTRIBUTES', 'WDFI', 'WDFI_ATTRIBUTES', 'WDFM', 'WDFM_ATTRIBUTES', 'WDMV', 'WDMV_ATTRIBUTES', 'WESD', 'WESD_ATTRIBUTES', 'WSF1', 'WSF1_ATTRIBUTES', 'WSF2', 'WSF2_ATTRIBUTES', 'WSF5', 'WSF5_ATTRIBUTES', 'WSFG', 'WSFG_ATTRIBUTES', 'WSFI', 'WSFI_ATTRIBUTES', 'WSFM', 'WSFM_ATTRIBUTES', 'SN12', 'SN12_ATTRIBUTES', 'SN32', 'SN32_ATTRIBUTES', 'SN52', 'SN52_ATTRIBUTES', 'SX12', 'SX12_ATTRIBUTES', 'SX32', 'SX32_ATTRIBUTES', 'SX52', 'SX52_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES', 'WT02', 'WT02_ATTRIBUTES', 'WT03', 'WT03_ATTRIBUTES', 'WT04', 'WT04_ATTRIBUTES', 'WT05', 'WT05_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES', 'WT07', 'WT07_ATTRIBUTES', 'WT08', 'WT08_ATTRIBUTES', 'WT09', 'WT09_ATTRIBUTES', 'WT10', 'WT10_ATTRIBUTES', 'WT11', 'WT11_ATTRIBUTES', 'WT13', 'WT13_ATTRIBUTES', 'WT14', 'WT14_ATTRIBUTES', 'WT15', 'WT15_ATTRIBUTES', 'WT16', 'WT16_ATTRIBUTES', 'WT17', 'WT17_ATTRIBUTES', 'WT18', 'WT18_ATTRIBUTES', 'WT19', 'WT19_ATTRIBUTES', 'WT21', 'WT21_ATTRIBUTES', 'WT22', 'WT22_ATTRIBUTES', 'WV03', 'WV03_ATTRIBUTES']\n",
      "Keeping columns: ['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'PRCP', 'PRCP_ATTRIBUTES', 'SNOW', 'SNOW_ATTRIBUTES']\n",
      "Shape after column selection: (32294, 10)\n",
      "Successfully converted column 'DATE' to datetime using format '%Y-%m-%d'\n",
      "Removed 0 duplicate rows. Remaining rows: 32294\n",
      "Shape after cleaning: (32294, 10)\n",
      "\n",
      "Creating plots for Bweather.csv...\n",
      "Saved summary plot: Bweather_summary.png\n",
      "  Saved LATITUDE distribution plot\n",
      "  Saved LONGITUDE distribution plot\n",
      "  Saved ELEVATION distribution plot\n",
      "  Saved PRCP distribution plot\n",
      "  Saved SNOW distribution plot\n",
      "\n",
      "Exporting Bweather.csv to SQL Server...\n",
      "Successfully exported to table: Weather_Bweather\n",
      "Export logged to: C:\\Aru_New_Future\\Mella-Technollogy-LLC-Python-Course-main\\Mella-Technollogy-LLC-Python-Course-main\\Backups\\Week_2\\Multiple_Files\\data\\export_log.csv\n",
      "\n",
      "Completed processing: Bweather.csv\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROCESSING FILE: Cweather.csv\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:30: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (31552, 144)\n",
      "Original columns: ['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'PRCP', 'PRCP_ATTRIBUTES', 'SNOW', 'SNOW_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES', 'TMAX', 'TMAX_ATTRIBUTES', 'TMIN', 'TMIN_ATTRIBUTES', 'ACSH', 'ACSH_ATTRIBUTES', 'ADPT', 'ADPT_ATTRIBUTES', 'ASLP', 'ASLP_ATTRIBUTES', 'ASTP', 'ASTP_ATTRIBUTES', 'AWBT', 'AWBT_ATTRIBUTES', 'AWND', 'AWND_ATTRIBUTES', 'DAEV', 'DAEV_ATTRIBUTES', 'DAWM', 'DAWM_ATTRIBUTES', 'EVAP', 'EVAP_ATTRIBUTES', 'FMTM', 'FMTM_ATTRIBUTES', 'FRGB', 'FRGB_ATTRIBUTES', 'FRGT', 'FRGT_ATTRIBUTES', 'FRTH', 'FRTH_ATTRIBUTES', 'GAHT', 'GAHT_ATTRIBUTES', 'MDEV', 'MDEV_ATTRIBUTES', 'MDWM', 'MDWM_ATTRIBUTES', 'MNPN', 'MNPN_ATTRIBUTES', 'MXPN', 'MXPN_ATTRIBUTES', 'PGTM', 'PGTM_ATTRIBUTES', 'PSUN', 'PSUN_ATTRIBUTES', 'RHAV', 'RHAV_ATTRIBUTES', 'RHMN', 'RHMN_ATTRIBUTES', 'RHMX', 'RHMX_ATTRIBUTES', 'TAVG', 'TAVG_ATTRIBUTES', 'TOBS', 'TOBS_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WDF1', 'WDF1_ATTRIBUTES', 'WDF2', 'WDF2_ATTRIBUTES', 'WDF5', 'WDF5_ATTRIBUTES', 'WDFG', 'WDFG_ATTRIBUTES', 'WDMV', 'WDMV_ATTRIBUTES', 'WESD', 'WESD_ATTRIBUTES', 'WSF1', 'WSF1_ATTRIBUTES', 'WSF2', 'WSF2_ATTRIBUTES', 'WSF5', 'WSF5_ATTRIBUTES', 'WSFG', 'WSFG_ATTRIBUTES', 'SN02', 'SN02_ATTRIBUTES', 'SN51', 'SN51_ATTRIBUTES', 'SN52', 'SN52_ATTRIBUTES', 'SX02', 'SX02_ATTRIBUTES', 'SX52', 'SX52_ATTRIBUTES', 'WT01', 'WT01_ATTRIBUTES', 'WT02', 'WT02_ATTRIBUTES', 'WT03', 'WT03_ATTRIBUTES', 'WT04', 'WT04_ATTRIBUTES', 'WT05', 'WT05_ATTRIBUTES', 'WT06', 'WT06_ATTRIBUTES', 'WT07', 'WT07_ATTRIBUTES', 'WT08', 'WT08_ATTRIBUTES', 'WT09', 'WT09_ATTRIBUTES', 'WT10', 'WT10_ATTRIBUTES', 'WT11', 'WT11_ATTRIBUTES', 'WT12', 'WT12_ATTRIBUTES', 'WT13', 'WT13_ATTRIBUTES', 'WT14', 'WT14_ATTRIBUTES', 'WT15', 'WT15_ATTRIBUTES', 'WT16', 'WT16_ATTRIBUTES', 'WT17', 'WT17_ATTRIBUTES', 'WT18', 'WT18_ATTRIBUTES', 'WT19', 'WT19_ATTRIBUTES', 'WT21', 'WT21_ATTRIBUTES', 'WT22', 'WT22_ATTRIBUTES', 'WV03', 'WV03_ATTRIBUTES', 'WV20', 'WV20_ATTRIBUTES']\n",
      "Keeping columns: ['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'PRCP', 'PRCP_ATTRIBUTES', 'SNOW', 'SNOW_ATTRIBUTES']\n",
      "Shape after column selection: (31552, 10)\n",
      "Successfully converted column 'DATE' to datetime using format '%Y-%m-%d'\n",
      "Removed 0 duplicate rows. Remaining rows: 31552\n",
      "Shape after cleaning: (31552, 10)\n",
      "\n",
      "Creating plots for Cweather.csv...\n",
      "Saved summary plot: Cweather_summary.png\n",
      "  Saved LATITUDE distribution plot\n",
      "  Saved LONGITUDE distribution plot\n",
      "  Saved ELEVATION distribution plot\n",
      "  Saved PRCP distribution plot\n",
      "  Saved SNOW distribution plot\n",
      "\n",
      "Exporting Cweather.csv to SQL Server...\n",
      "Successfully exported to table: Weather_Cweather\n",
      "Export logged to: C:\\Aru_New_Future\\Mella-Technollogy-LLC-Python-Course-main\\Mella-Technollogy-LLC-Python-Course-main\\Backups\\Week_2\\Multiple_Files\\data\\export_log.csv\n",
      "\n",
      "Completed processing: Cweather.csv\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PROCESSING COMPLETE!\n",
      "============================================================\n",
      "Total files processed: 3\n",
      "Plots saved in: C:\\Aru_New_Future\\Mella-Technollogy-LLC-Python-Course-main\\Mella-Technollogy-LLC-Python-Course-main\\Backups\\Week_2\\Multiple_Files\\data\\Plots\n",
      "All data exported to SQL Server database: Stu_Database\n",
      "Each file exported to separate table with 'Weather_' prefix\n",
      "\n",
      "Export Summary:\n",
      "    filename       table_name  original_rows  cleaned_rows  kept_columns  missing_columns                export_time\n",
      "Aweather.csv Weather_Aweather          45841         45841            10                0 2025-09-06 14:01:47.522625\n",
      "Bweather.csv Weather_Bweather          32294         32294            10                0 2025-09-06 14:01:56.777072\n",
      "Cweather.csv Weather_Cweather          31552         31552            10                0 2025-09-06 14:02:11.834131\n",
      "\n",
      "Column Availability Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,105,115,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Column  Available_In_Files Availability_Percentage\n",
      "        STATION                   3                  100.0%\n",
      "           DATE                   3                  100.0%\n",
      "       LATITUDE                   3                  100.0%\n",
      "      LONGITUDE                   3                  100.0%\n",
      "      ELEVATION                   3                  100.0%\n",
      "           NAME                   3                  100.0%\n",
      "           PRCP                   3                  100.0%\n",
      "PRCP_ATTRIBUTES                   3                  100.0%\n",
      "           SNOW                   3                  100.0%\n",
      "SNOW_ATTRIBUTES                   3                  100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abreh\\AppData\\Local\\Temp\\ipykernel_27884\\3931124796.py:224: DtypeWarning: Columns (17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,101,107,109,111,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################################\n",
    "import Mella_python_data_analytics as mella # This is the New Module that developed by the first Batch students\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "###############################################################################################\n",
    "conn_str = \"\" # Create Your Own connection String\n",
    "folder_path = r\"\" # Put your own directory path\n",
    "###############################################################################################\n",
    "plots_dir = os.path.join(folder_path, \"Plots\")\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "###############################################################################################\n",
    "columns_to_keep = [\n",
    "    'STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'PRCP',\n",
    "    'PRCP_ATTRIBUTES', 'SNOW', 'SNOW_ATTRIBUTES'\n",
    "]\n",
    "###############################################################################################\n",
    "dataframes_dict = mella.read_individual_csv_files(folder_path)\n",
    "csv_files = list(dataframes_dict.keys())\n",
    "print(f\"Found {len(csv_files)} CSV files to process\")\n",
    "###############################################################################################\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROCESSING FILE: {csv_file}\")\n",
    "    print(f\"{'='*60}\")\n",
    "###############################################################################################\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "###############################################################################################    \n",
    "    available_columns = [col for col in columns_to_keep if col in df.columns]\n",
    "    missing_columns = [col for col in columns_to_keep if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Missing columns: {missing_columns}\")\n",
    "###############################################################################################   \n",
    "    df_processed = df[available_columns].copy()\n",
    "    df_processed = mella.handle_missing_values(df_processed, method=\"fill\")\n",
    "###############################################################################################    \n",
    "\n",
    "    if 'DATE' in df_processed.columns:\n",
    "        df_processed = mella.convert_datetime_column(df_processed, \"DATE\", format=\"%Y-%m-%d\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    duplicate_cols = []\n",
    "    if 'STATION' in df_processed.columns and 'DATE' in df_processed.columns:\n",
    "        duplicate_cols = [\"STATION\", \"DATE\"]\n",
    "    elif 'STATION' in df_processed.columns:\n",
    "        duplicate_cols = [\"STATION\"]\n",
    "    \n",
    "    if duplicate_cols:\n",
    "        df_processed = mella.drop_duplicates(df_processed, subset=duplicate_cols, keep='first')\n",
    "    else:\n",
    "        df_processed = mella.drop_duplicates(df_processed, keep='first')\n",
    "    \n",
    "    print(f\"Shape after cleaning: {df_processed.shape}\")\n",
    "    \n",
    "    # Convert numeric columns\n",
    "    numeric_cols_to_convert = ['PRCP', 'SNOW', 'LATITUDE', 'LONGITUDE', 'ELEVATION']\n",
    "    for col in numeric_cols_to_convert:\n",
    "        if col in df_processed.columns:\n",
    "            df_processed = mella.convert_to_numeric(df_processed, col)\n",
    "# Don't worry much about the simulations block **********************************************************   \n",
    "    # Plotings, subplots\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    fig.suptitle(f\"Analysis of {csv_file}\", fontsize=16, fontweight='bold')\n",
    "\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    available_count = len(available_columns)\n",
    "    missing_count = len(missing_columns)\n",
    "    ax1.pie([available_count, missing_count], \n",
    "            labels=['Available', 'Missing'], autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])\n",
    "    ax1.set_title('Requested Columns Availability')\n",
    "    \n",
    "    # Plot 2: Missing values in kept columns\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    missing_values = df_processed.isnull().sum()\n",
    "    missing_values = missing_values[missing_values > 0]\n",
    "    if len(missing_values) > 0:\n",
    "        ax2.bar(missing_values.index, missing_values.values, color='orange')\n",
    "        ax2.set_title('Missing Values in Kept Columns')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No missing values', ha='center', va='center', transform=ax2.transAxes)\n",
    "        ax2.set_title('Missing Values')\n",
    "    \n",
    "    # Plot 3: Precipitation distribution (if available)\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    if 'PRCP' in df_processed.columns:\n",
    "        prcp_data = df_processed['PRCP'].dropna()\n",
    "        if len(prcp_data) > 0:\n",
    "            ax3.hist(prcp_data, bins=20, alpha=0.7, color='skyblue')\n",
    "            ax3.set_title('Precipitation (PRCP) Distribution')\n",
    "            ax3.set_xlabel('Precipitation')\n",
    "            ax3.set_ylabel('Frequency')\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'No PRCP data', ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax3.set_title('Precipitation Data')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'PRCP column not available', ha='center', va='center', transform=ax3.transAxes)\n",
    "        ax3.set_title('Precipitation Data')\n",
    "    \n",
    "    # Plot 4: File summary\n",
    "    ax4 = plt.subplot(2, 2, 4)\n",
    "    ax4.axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "    File: {csv_file}\n",
    "    Original Records: {len(df)}\n",
    "    Cleaned Records: {len(df_processed)}\n",
    "    Kept Columns: {len(available_columns)}\n",
    "    Missing Columns: {len(missing_columns)}\n",
    "    Stations: {df_processed['STATION'].nunique() if 'STATION' in df_processed.columns else 'N/A'}\n",
    "    \"\"\"\n",
    "    ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, fontfamily='monospace',\n",
    "             verticalalignment='top', fontsize=10)\n",
    "    ax4.set_title('File Summary')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the summary plot\n",
    "    plot_filename = os.path.splitext(csv_file)[0] + '_summary.png'\n",
    "    plot_path = os.path.join(plots_dir, plot_filename)\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved summary plot: {plot_filename}\")\n",
    "    # Create individual plots for numeric columns\n",
    "    numeric_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.hist(df_processed[col].dropna(), bins=20, alpha=0.7, color='lightseagreen')\n",
    "            plt.title(f'Distribution of {col} - {csv_file}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Save individual plot\n",
    "            col_plot_filename = os.path.splitext(csv_file)[0] + f'_{col}_distribution.png'\n",
    "            col_plot_path = os.path.join(plots_dir, col_plot_filename)\n",
    "            plt.savefig(col_plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"  Saved {col} distribution plot\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error creating plot for {col}: {e}\")\n",
    "# Don't worry much about the simulations block ********************************************************** \n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   This the Integration Block between SQL and Python   %%%%%%%%%%%%%%\n",
    "    print(f\"\\nExporting {csv_file} to SQL Server...\")\n",
    "    try:\n",
    "        # You can give a proper short names for your tables to be export to SQL\n",
    "        table_name = os.path.splitext(csv_file)[0]\n",
    "        table_name = ''.join(c for c in table_name if c.isalnum() or c in ['_', ' '])\n",
    "        table_name = table_name.replace(' ', '_') \n",
    "        table_name = f\"Weather_{table_name}\"  \n",
    "\n",
    "        if len(table_name) > 100:\n",
    "            table_name = table_name[:100]\n",
    "        \n",
    "        mella.export_to_mssql(df_processed, table_name, conn_str)\n",
    "        print(f\"Successfully exported to table: {table_name}\")\n",
    "\n",
    "        export_summary = pd.DataFrame({\n",
    "            'filename': [csv_file],\n",
    "            'table_name': [table_name],\n",
    "            'original_rows': [len(df)],\n",
    "            'cleaned_rows': [len(df_processed)],\n",
    "            'kept_columns': [len(available_columns)],\n",
    "            'missing_columns': [len(missing_columns)],\n",
    "            'export_time': [pd.Timestamp.now()]\n",
    "        })\n",
    "        \n",
    "        export_log_path = os.path.join(folder_path, \"export_log.csv\")\n",
    "        if os.path.exists(export_log_path):\n",
    "            export_log = pd.read_csv(export_log_path)\n",
    "            export_log = pd.concat([export_log, export_summary], ignore_index=True)\n",
    "        else:\n",
    "            export_log = export_summary\n",
    "        \n",
    "        export_log.to_csv(export_log_path, index=False)\n",
    "        print(f\"Export logged to: {export_log_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting {csv_file} to database: {e}\")\n",
    "    \n",
    "    print(f\"\\nCompleted processing: {csv_file}\")\n",
    "\n",
    "#    You can Uncomment the commented lines here below, if you want to seed the direct outputs\n",
    "#     print(f\"{'='*60}\")\n",
    "# print(f\"\\n{'='*60}\")\n",
    "# print(\"PROCESSING COMPLETE!\")\n",
    "# print(f\"{'='*60}\")\n",
    "# print(f\"Total files processed: {len(csv_files)}\")\n",
    "# print(f\"Plots saved in: {plots_dir}\")\n",
    "# print(f\"All data exported to SQL Server database: Stu_Database\")\n",
    "# print(f\"Each file exported to separate table with 'Weather_' prefix\")\n",
    "# Show column availability summary\n",
    "\n",
    "print(f\"\\nColumn Availability Summary:\")\n",
    "column_availability = {}\n",
    "for col in columns_to_keep:\n",
    "    column_availability[col] = sum(1 for csv_file in csv_files if col in pd.read_csv(os.path.join(folder_path, csv_file)).columns)\n",
    "\n",
    "availability_df = pd.DataFrame({\n",
    "    'Column': columns_to_keep,\n",
    "    'Available_In_Files': [column_availability[col] for col in columns_to_keep],\n",
    "    'Availability_Percentage': [f\"{(column_availability[col] / len(csv_files)) * 100:.1f}%\" for col in columns_to_keep]\n",
    "})\n",
    "\n",
    "print(availability_df.to_string(index=False))\n",
    "# GOOD LUCK Mella-Python Group, Thank you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7f5c27-9c99-4b1c-91e9-607512d8fed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESSING FILE: 4\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESSING FILE: {4}\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2995f6-c92b-41bd-b2b5-8136f99c217e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Mella)",
   "language": "python",
   "name": "mella"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
